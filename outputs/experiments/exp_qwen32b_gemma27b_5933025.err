
Lmod is automatically replacing "gnu9/9.3.0" with "gnu10/10.3.0-ya".


Inactive Modules:
  1) hwloc/2.1.0     2) libfabric     3) ucx

The following have been reloaded with a version change:
  1) openmpi4/4.0.4 => openmpi4/4.1.2-4a

/scratch/mrahma45/jailbreaking_repos/venv_jailbreak/lib/python3.9/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2026-02-25 07:17:39,437 - __main__ - INFO - Initializing agents...
2026-02-25 07:17:39,438 - jailbreak.agentic_module.agents.attacker - INFO - Initializing AttackerAgent
`torch_dtype` is deprecated! Use `dtype` instead!
2026-02-25 07:17:43,411 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▌         | 1/17 [00:06<01:50,  6.89s/it]Loading checkpoint shards:  12%|█▏        | 2/17 [00:12<01:27,  5.85s/it]Loading checkpoint shards:  18%|█▊        | 3/17 [00:18<01:23,  5.94s/it]Loading checkpoint shards:  24%|██▎       | 4/17 [00:24<01:17,  5.96s/it]Loading checkpoint shards:  29%|██▉       | 5/17 [00:29<01:07,  5.63s/it]Loading checkpoint shards:  35%|███▌      | 6/17 [00:35<01:03,  5.81s/it]Loading checkpoint shards:  41%|████      | 7/17 [00:42<01:03,  6.31s/it]Loading checkpoint shards:  47%|████▋     | 8/17 [00:50<01:00,  6.74s/it]Loading checkpoint shards:  53%|█████▎    | 9/17 [00:57<00:54,  6.83s/it]Loading checkpoint shards:  59%|█████▉    | 10/17 [01:03<00:46,  6.71s/it]Loading checkpoint shards:  65%|██████▍   | 11/17 [01:10<00:40,  6.78s/it]Loading checkpoint shards:  71%|███████   | 12/17 [01:17<00:33,  6.68s/it]Loading checkpoint shards:  76%|███████▋  | 13/17 [01:24<00:27,  6.80s/it]Loading checkpoint shards:  82%|████████▏ | 14/17 [01:29<00:19,  6.45s/it]Loading checkpoint shards:  88%|████████▊ | 15/17 [01:34<00:12,  6.02s/it]Loading checkpoint shards:  94%|█████████▍| 16/17 [01:40<00:06,  6.01s/it]Loading checkpoint shards: 100%|██████████| 17/17 [01:46<00:00,  5.85s/it]Loading checkpoint shards: 100%|██████████| 17/17 [01:46<00:00,  6.25s/it]
2026-02-25 07:19:29,974 - jailbreak.agentic_module.agents.attacker - INFO - Successfully created attacker LLM: QwenText(model_id=Qwen/Qwen3-32B, loaded=True)
2026-02-25 07:19:30,749 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▌         | 1/17 [00:02<00:32,  2.02s/it]Loading checkpoint shards:  12%|█▏        | 2/17 [00:04<00:37,  2.53s/it]Loading checkpoint shards:  18%|█▊        | 3/17 [00:07<00:37,  2.69s/it]Loading checkpoint shards:  24%|██▎       | 4/17 [00:10<00:35,  2.76s/it]Loading checkpoint shards:  29%|██▉       | 5/17 [00:13<00:33,  2.83s/it]Loading checkpoint shards:  35%|███▌      | 6/17 [00:16<00:31,  2.84s/it]Loading checkpoint shards:  41%|████      | 7/17 [00:19<00:28,  2.85s/it]Loading checkpoint shards:  47%|████▋     | 8/17 [00:22<00:25,  2.86s/it]Loading checkpoint shards:  53%|█████▎    | 9/17 [00:25<00:22,  2.87s/it]Loading checkpoint shards:  59%|█████▉    | 10/17 [00:27<00:20,  2.87s/it]Loading checkpoint shards:  65%|██████▍   | 11/17 [00:30<00:17,  2.88s/it]Loading checkpoint shards:  71%|███████   | 12/17 [00:33<00:14,  2.89s/it]Loading checkpoint shards:  76%|███████▋  | 13/17 [00:36<00:11,  2.88s/it]Loading checkpoint shards:  82%|████████▏ | 14/17 [00:39<00:08,  2.88s/it]Loading checkpoint shards:  88%|████████▊ | 15/17 [00:42<00:05,  2.87s/it]Loading checkpoint shards:  94%|█████████▍| 16/17 [00:45<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:46<00:00,  2.43s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:46<00:00,  2.74s/it]
2026-02-25 07:20:17,603 - jailbreak.agentic_module.agents.attacker - INFO - Successfully created reasoning LLM: QwenText(model_id=Qwen/Qwen3-32B, loaded=True)
2026-02-25 07:20:17,611 - jailbreak.agentic_module.agents.utils - INFO - Successfully loaded tactics from /scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/agentic_module/agents/initial_tactics.json
2026-02-25 07:20:17,611 - jailbreak.agentic_module.agents.attacker - INFO - KnowledgeBase initialized with 6 tactics
2026-02-25 07:20:17,611 - jailbreak.agentic_module.agents.attacker - INFO - AttackerAgent initialized successfully
2026-02-25 07:20:17,611 - __main__ - INFO - AttackerAgent initialized
2026-02-25 07:20:17,611 - jailbreak.agentic_module.agents.target - INFO - Initializing TargetAgent
2026-02-25 07:20:17,611 - jailbreak.agentic_module.agents.target - ERROR - Failed to create target LLM: Unsupported model: 'gemma'. Supported models: ['llama', 'gpt', 'phi', 'qwen', 'deepseek', 'aya']
Traceback (most recent call last):
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 476, in <module>
    main(config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 463, in main
    orchestrator = PipelineOrchestrator(config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 83, in __init__
    self._initialize_agents()
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 114, in _initialize_agents
    self.target = TargetAgent(target_config=target_config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/agentic_module/agents/target.py", line 36, in __init__
    self.target_llm = llm_model_factory(target_config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/llm_module/model_factory.py", line 78, in llm_model_factory
    raise ValueError(f"Unsupported model: '{model_type}'. Supported models: {supported_models}")
ValueError: Unsupported model: 'gemma'. Supported models: ['llama', 'gpt', 'phi', 'qwen', 'deepseek', 'aya']
