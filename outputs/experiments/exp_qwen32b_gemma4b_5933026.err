
Lmod is automatically replacing "gnu9/9.3.0" with "gnu10/10.3.0-ya".


Inactive Modules:
  1) hwloc/2.1.0     2) libfabric     3) ucx

The following have been reloaded with a version change:
  1) openmpi4/4.0.4 => openmpi4/4.1.2-4a

/scratch/mrahma45/jailbreaking_repos/venv_jailbreak/lib/python3.9/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2026-02-25 07:21:11,552 - __main__ - INFO - Initializing agents...
2026-02-25 07:21:11,553 - jailbreak.agentic_module.agents.attacker - INFO - Initializing AttackerAgent
`torch_dtype` is deprecated! Use `dtype` instead!
2026-02-25 07:21:15,321 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▌         | 1/17 [00:06<01:46,  6.65s/it]Loading checkpoint shards:  12%|█▏        | 2/17 [00:12<01:34,  6.29s/it]Loading checkpoint shards:  18%|█▊        | 3/17 [00:18<01:23,  5.95s/it]Loading checkpoint shards:  24%|██▎       | 4/17 [00:24<01:19,  6.10s/it]Loading checkpoint shards:  29%|██▉       | 5/17 [00:31<01:16,  6.39s/it]Loading checkpoint shards:  35%|███▌      | 6/17 [00:38<01:12,  6.55s/it]Loading checkpoint shards:  41%|████      | 7/17 [00:45<01:07,  6.75s/it]Loading checkpoint shards:  47%|████▋     | 8/17 [00:50<00:55,  6.17s/it]Loading checkpoint shards:  53%|█████▎    | 9/17 [00:56<00:48,  6.01s/it]Loading checkpoint shards:  59%|█████▉    | 10/17 [01:02<00:43,  6.16s/it]Loading checkpoint shards:  65%|██████▍   | 11/17 [01:09<00:38,  6.33s/it]Loading checkpoint shards:  71%|███████   | 12/17 [01:15<00:31,  6.34s/it]Loading checkpoint shards:  76%|███████▋  | 13/17 [01:22<00:25,  6.50s/it]Loading checkpoint shards:  82%|████████▏ | 14/17 [01:27<00:18,  6.06s/it]Loading checkpoint shards:  88%|████████▊ | 15/17 [01:33<00:12,  6.06s/it]Loading checkpoint shards:  94%|█████████▍| 16/17 [01:41<00:06,  6.62s/it]Loading checkpoint shards: 100%|██████████| 17/17 [01:47<00:00,  6.49s/it]Loading checkpoint shards: 100%|██████████| 17/17 [01:47<00:00,  6.34s/it]
2026-02-25 07:23:03,320 - jailbreak.agentic_module.agents.attacker - INFO - Successfully created attacker LLM: QwenText(model_id=Qwen/Qwen3-32B, loaded=True)
2026-02-25 07:23:04,068 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▌         | 1/17 [00:02<00:32,  2.04s/it]Loading checkpoint shards:  12%|█▏        | 2/17 [00:05<00:39,  2.60s/it]Loading checkpoint shards:  18%|█▊        | 3/17 [00:08<00:39,  2.80s/it]Loading checkpoint shards:  24%|██▎       | 4/17 [00:10<00:36,  2.83s/it]Loading checkpoint shards:  29%|██▉       | 5/17 [00:13<00:33,  2.82s/it]Loading checkpoint shards:  35%|███▌      | 6/17 [00:16<00:31,  2.83s/it]Loading checkpoint shards:  41%|████      | 7/17 [00:19<00:28,  2.83s/it]Loading checkpoint shards:  47%|████▋     | 8/17 [00:22<00:25,  2.83s/it]Loading checkpoint shards:  53%|█████▎    | 9/17 [00:25<00:22,  2.82s/it]Loading checkpoint shards:  59%|█████▉    | 10/17 [00:27<00:19,  2.82s/it]Loading checkpoint shards:  65%|██████▍   | 11/17 [00:30<00:16,  2.81s/it]Loading checkpoint shards:  71%|███████   | 12/17 [00:33<00:14,  2.82s/it]Loading checkpoint shards:  76%|███████▋  | 13/17 [00:36<00:11,  2.81s/it]Loading checkpoint shards:  82%|████████▏ | 14/17 [00:39<00:08,  2.81s/it]Loading checkpoint shards:  88%|████████▊ | 15/17 [00:41<00:05,  2.80s/it]Loading checkpoint shards:  94%|█████████▍| 16/17 [00:44<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:46<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:46<00:00,  2.71s/it]
2026-02-25 07:23:50,352 - jailbreak.agentic_module.agents.attacker - INFO - Successfully created reasoning LLM: QwenText(model_id=Qwen/Qwen3-32B, loaded=True)
2026-02-25 07:23:50,368 - jailbreak.agentic_module.agents.utils - INFO - Successfully loaded tactics from /scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/agentic_module/agents/initial_tactics.json
2026-02-25 07:23:50,368 - jailbreak.agentic_module.agents.attacker - INFO - KnowledgeBase initialized with 6 tactics
2026-02-25 07:23:50,368 - jailbreak.agentic_module.agents.attacker - INFO - AttackerAgent initialized successfully
2026-02-25 07:23:50,368 - __main__ - INFO - AttackerAgent initialized
2026-02-25 07:23:50,368 - jailbreak.agentic_module.agents.target - INFO - Initializing TargetAgent
2026-02-25 07:23:50,368 - jailbreak.agentic_module.agents.target - ERROR - Failed to create target LLM: Unsupported model: 'gemma'. Supported models: ['llama', 'gpt', 'phi', 'qwen', 'deepseek', 'aya']
Traceback (most recent call last):
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 476, in <module>
    main(config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 463, in main
    orchestrator = PipelineOrchestrator(config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 83, in __init__
    self._initialize_agents()
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 114, in _initialize_agents
    self.target = TargetAgent(target_config=target_config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/agentic_module/agents/target.py", line 36, in __init__
    self.target_llm = llm_model_factory(target_config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/llm_module/model_factory.py", line 78, in llm_model_factory
    raise ValueError(f"Unsupported model: '{model_type}'. Supported models: {supported_models}")
ValueError: Unsupported model: 'gemma'. Supported models: ['llama', 'gpt', 'phi', 'qwen', 'deepseek', 'aya']
