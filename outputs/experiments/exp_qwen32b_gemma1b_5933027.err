
Lmod is automatically replacing "gnu9/9.3.0" with "gnu10/10.3.0-ya".


Inactive Modules:
  1) hwloc/2.1.0     2) libfabric     3) ucx

The following have been reloaded with a version change:
  1) openmpi4/4.0.4 => openmpi4/4.1.2-4a

/scratch/mrahma45/jailbreaking_repos/venv_jailbreak/lib/python3.9/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2026-02-25 07:24:43,866 - __main__ - INFO - Initializing agents...
2026-02-25 07:24:43,867 - jailbreak.agentic_module.agents.attacker - INFO - Initializing AttackerAgent
`torch_dtype` is deprecated! Use `dtype` instead!
2026-02-25 07:24:48,235 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▌         | 1/17 [00:06<01:50,  6.91s/it]Loading checkpoint shards:  12%|█▏        | 2/17 [00:12<01:28,  5.89s/it]Loading checkpoint shards:  18%|█▊        | 3/17 [00:18<01:23,  5.95s/it]Loading checkpoint shards:  24%|██▎       | 4/17 [00:22<01:09,  5.36s/it]Loading checkpoint shards:  29%|██▉       | 5/17 [00:27<01:01,  5.15s/it]Loading checkpoint shards:  35%|███▌      | 6/17 [00:32<00:56,  5.17s/it]Loading checkpoint shards:  41%|████      | 7/17 [00:40<00:59,  5.98s/it]Loading checkpoint shards:  47%|████▋     | 8/17 [00:46<00:55,  6.20s/it]Loading checkpoint shards:  53%|█████▎    | 9/17 [00:54<00:52,  6.60s/it]Loading checkpoint shards:  59%|█████▉    | 10/17 [01:00<00:44,  6.35s/it]Loading checkpoint shards:  65%|██████▍   | 11/17 [01:06<00:38,  6.38s/it]Loading checkpoint shards:  71%|███████   | 12/17 [01:12<00:31,  6.35s/it]Loading checkpoint shards:  76%|███████▋  | 13/17 [01:18<00:25,  6.27s/it]Loading checkpoint shards:  82%|████████▏ | 14/17 [01:25<00:19,  6.45s/it]Loading checkpoint shards:  88%|████████▊ | 15/17 [01:32<00:12,  6.47s/it]Loading checkpoint shards:  94%|█████████▍| 16/17 [01:38<00:06,  6.47s/it]Loading checkpoint shards: 100%|██████████| 17/17 [01:45<00:00,  6.62s/it]Loading checkpoint shards: 100%|██████████| 17/17 [01:45<00:00,  6.22s/it]
2026-02-25 07:26:34,287 - jailbreak.agentic_module.agents.attacker - INFO - Successfully created attacker LLM: QwenText(model_id=Qwen/Qwen3-32B, loaded=True)
2026-02-25 07:26:35,045 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▌         | 1/17 [00:02<00:32,  2.00s/it]Loading checkpoint shards:  12%|█▏        | 2/17 [00:04<00:37,  2.52s/it]Loading checkpoint shards:  18%|█▊        | 3/17 [00:07<00:37,  2.69s/it]Loading checkpoint shards:  24%|██▎       | 4/17 [00:10<00:36,  2.78s/it]Loading checkpoint shards:  29%|██▉       | 5/17 [00:13<00:33,  2.81s/it]Loading checkpoint shards:  35%|███▌      | 6/17 [00:16<00:31,  2.83s/it]Loading checkpoint shards:  41%|████      | 7/17 [00:19<00:28,  2.84s/it]Loading checkpoint shards:  47%|████▋     | 8/17 [00:22<00:25,  2.84s/it]Loading checkpoint shards:  53%|█████▎    | 9/17 [00:24<00:22,  2.84s/it]Loading checkpoint shards:  59%|█████▉    | 10/17 [00:27<00:20,  2.86s/it]Loading checkpoint shards:  65%|██████▍   | 11/17 [00:30<00:17,  2.87s/it]Loading checkpoint shards:  71%|███████   | 12/17 [00:33<00:14,  2.89s/it]Loading checkpoint shards:  76%|███████▋  | 13/17 [00:36<00:11,  2.88s/it]Loading checkpoint shards:  82%|████████▏ | 14/17 [00:39<00:08,  2.85s/it]Loading checkpoint shards:  88%|████████▊ | 15/17 [00:42<00:05,  2.86s/it]Loading checkpoint shards:  94%|█████████▍| 16/17 [00:45<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:46<00:00,  2.43s/it]Loading checkpoint shards: 100%|██████████| 17/17 [00:46<00:00,  2.74s/it]
2026-02-25 07:27:21,791 - jailbreak.agentic_module.agents.attacker - INFO - Successfully created reasoning LLM: QwenText(model_id=Qwen/Qwen3-32B, loaded=True)
2026-02-25 07:27:21,806 - jailbreak.agentic_module.agents.utils - INFO - Successfully loaded tactics from /scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/agentic_module/agents/initial_tactics.json
2026-02-25 07:27:21,807 - jailbreak.agentic_module.agents.attacker - INFO - KnowledgeBase initialized with 6 tactics
2026-02-25 07:27:21,807 - jailbreak.agentic_module.agents.attacker - INFO - AttackerAgent initialized successfully
2026-02-25 07:27:21,807 - __main__ - INFO - AttackerAgent initialized
2026-02-25 07:27:21,807 - jailbreak.agentic_module.agents.target - INFO - Initializing TargetAgent
2026-02-25 07:27:21,807 - jailbreak.agentic_module.agents.target - ERROR - Failed to create target LLM: Unsupported model: 'gemma'. Supported models: ['llama', 'gpt', 'phi', 'qwen', 'deepseek', 'aya']
Traceback (most recent call last):
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 476, in <module>
    main(config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 463, in main
    orchestrator = PipelineOrchestrator(config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 83, in __init__
    self._initialize_agents()
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/orchestrator.py", line 114, in _initialize_agents
    self.target = TargetAgent(target_config=target_config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/agentic_module/agents/target.py", line 36, in __init__
    self.target_llm = llm_model_factory(target_config)
  File "/scratch/mrahma45/jailbreaking_repos/jailbreak-pkg/runs/pipeline/../../jailbreak/llm_module/model_factory.py", line 78, in llm_model_factory
    raise ValueError(f"Unsupported model: '{model_type}'. Supported models: {supported_models}")
ValueError: Unsupported model: 'gemma'. Supported models: ['llama', 'gpt', 'phi', 'qwen', 'deepseek', 'aya']
